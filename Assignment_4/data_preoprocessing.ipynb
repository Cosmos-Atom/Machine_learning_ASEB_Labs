{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rowid     kepid kepoi_name   kepler_name koi_disposition koi_vet_stat  \\\n",
      "0      1  10797460  K00752.01  Kepler-227 b       CONFIRMED         Done   \n",
      "1      2  10797460  K00752.02  Kepler-227 c       CONFIRMED         Done   \n",
      "2      3  10811496  K00753.01           NaN       CANDIDATE         Done   \n",
      "3      4  10848459  K00754.01           NaN  FALSE POSITIVE         Done   \n",
      "4      5  10854555  K00755.01  Kepler-664 b       CONFIRMED         Done   \n",
      "\n",
      "  koi_vet_date koi_pdisposition  koi_score  koi_fpflag_nt  ...  koi_fwm_srao  \\\n",
      "0   2018-08-16        CANDIDATE      1.000              0  ...         0.430   \n",
      "1   2018-08-16        CANDIDATE      0.969              0  ...        -0.630   \n",
      "2   2018-08-16        CANDIDATE      0.000              0  ...        -0.021   \n",
      "3   2018-08-16   FALSE POSITIVE      0.000              0  ...        -0.111   \n",
      "4   2018-08-16        CANDIDATE      1.000              0  ...        -0.010   \n",
      "\n",
      "   koi_fwm_sdeco  koi_fwm_prao koi_fwm_pdeco koi_dicco_mra  koi_dicco_mdec  \\\n",
      "0          0.940      -0.00020      -0.00055        -0.010           0.200   \n",
      "1          1.230       0.00066      -0.00105         0.390           0.000   \n",
      "2         -0.038       0.00070       0.00060        -0.025          -0.034   \n",
      "3          0.002       0.00302      -0.00142        -0.249           0.147   \n",
      "4          0.230       0.00008      -0.00007         0.030          -0.090   \n",
      "\n",
      "   koi_dicco_msky  koi_dikco_mra  koi_dikco_mdec  koi_dikco_msky  \n",
      "0           0.200          0.080           0.310           0.320  \n",
      "1           0.390          0.490           0.120           0.500  \n",
      "2           0.042          0.002          -0.027           0.027  \n",
      "3           0.289         -0.257           0.099           0.276  \n",
      "4           0.100          0.070           0.020           0.070  \n",
      "\n",
      "[5 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('koi_dataset.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "\n",
    "\n",
    "# Write the results to a new file\n",
    "with open('null_values.txt', 'w') as file:\n",
    "    file.write(\"Column Name\\tNull Count\\n\")\n",
    "    for column, count in null_counts.items():\n",
    "        file.write(f\"{column}\\t{count}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = [\"kepler_name\", \"koi_comment\", \"koi_longp\", \"koi_model_dof\", \"koi_model_chisq\", \"koi_sage\", \"koi_ingress\", \"kepoi_name\", \"koi_vet_date\", \"koi_limbdark_mod\", \"koi_parm_prov\", \"koi_tce_delivname\", \"koi_sparprov\", \"koi_datalink_dvr\", \"koi_datalink_dvs\", \"koi_quarters\", \"koi_trans_mod\"]\n",
    "\n",
    "# Drop the specified columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['koi_disposition'])  \n",
    "y = df['koi_disposition']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_data = df.dtypes\n",
    "\n",
    "# Write the results to a new file\n",
    "with open('data_types.txt', 'w') as file:\n",
    "    file.write(\"Column Name\\tData Type\\n\")\n",
    "    for column, count in types_data.items():\n",
    "        file.write(f\"{column}\\t{count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_desc = df.describe()\n",
    "\n",
    "# Write the results to a new file\n",
    "with open('data_description.txt', 'w') as file:\n",
    "    file.write(\"Column Name\\tData description\\n\")\n",
    "    for column, count in types_data.items():\n",
    "        file.write(f\"{column}\\t{count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Perform one-hot encoding for object columns\n",
    "df_encoded = pd.get_dummies(X, columns=object_columns)\n",
    "types_data2 = df_encoded.dtypes\n",
    "\n",
    "# Write the results to a new file\n",
    "with open('data_types2.txt', 'w') as file:\n",
    "    file.write(\"Column Name\\tData Type\\n\")\n",
    "    for column, count in types_data2.items():\n",
    "        file.write(f\"{column}\\t{count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('box_plots'):\n",
    "    os.makedirs('box_plots')\n",
    "\n",
    "# Iterate over each numerical feature\n",
    "for column in df_encoded.select_dtypes(include='number').columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=df_encoded[column])\n",
    "    plt.title(f'Box Plot of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Values')\n",
    "    \n",
    "    plt.savefig(f'box_plots/{column}_boxplot.png')\n",
    "    \n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns with missing values found.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize SimpleImputer with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Define columns with missing values\n",
    "columns_with_missing_values = df_encoded.columns[df_encoded.isnull().any()].tolist()\n",
    "\n",
    "# Check if there are columns with missing values\n",
    "if not columns_with_missing_values:\n",
    "    print(\"No columns with missing values found.\")\n",
    "    df_encoded['koi_disposition'] = df[\"koi_disposition\"]\n",
    "    df_encoded.to_csv('imputed_data.csv', index=False)\n",
    "else:\n",
    "    # Extract data for columns with missing values\n",
    "    data_to_impute = df_encoded[columns_with_missing_values].values\n",
    "\n",
    "    # Perform imputation on columns with missing values\n",
    "    imputed_data = imputer.fit_transform(data_to_impute)\n",
    "\n",
    "    # Create a DataFrame from the imputed data\n",
    "    df_imputed = pd.DataFrame(imputed_data, columns=columns_with_missing_values, index=df_encoded.index)\n",
    "\n",
    "    # Replace missing values in the original DataFrame with imputed values\n",
    "    df_encoded[columns_with_missing_values] = df_imputed\n",
    "\n",
    "    # Add target variable to the imputed DataFrame\n",
    "    df_imputed['koi_disposition'] = df_encoded['koi_disposition']\n",
    "\n",
    "    # Save the imputed DataFrame to a new file\n",
    "    df_encoded.to_csv('imputed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts_en = df_encoded.isnull().sum()\n",
    "\n",
    "\n",
    "# Write the results to a new file\n",
    "with open('null_values_encoded.txt', 'w') as file:\n",
    "    file.write(\"Column Name\\tNull Count\\n\")\n",
    "    for column, count in null_counts_en.items():\n",
    "        file.write(f\"{column}\\t{count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
